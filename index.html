<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- Primary Meta Tags -->
  <meta name="title"
    content="VenusBench-GD: A Comprehensive Multi-Platform GUI Benchmark for Diverse Grounding Tasks - Beitong Zhou, Zhexiao Huang, Yuan Guo, Zhangxuan Gu, Tianyu Xia, Zichen Luo, Fei Tang, Dehan Kong, Yanyi Shang, Suling Ou, Zhenlin Guo, Changhua Meng, Shuheng Shen">
  <meta name="description"
    content="VenusBench-GD addresses the limitations of existing GUI grounding benchmarks by introducing a large-scale, bilingual, and cross-platform evaluation framework that utilizes a rigorous high-quality data construction pipeline. The study proposes a novel hierarchical taxonomy encompassing six subtasks across basic and advanced categories, specifically designed to evaluate models on functional understanding and multi-step reasoning. Key experimental findings reveal that while general-purpose multimodal models have reached performance saturation on basic tasks, specialized GUI modelsâ€”though capable in advanced scenariosâ€”suffer from significant overfitting and poor robustness, underscoring the necessity of this comprehensive, multi-tiered framework for future GUI agent development.">
  <meta name="keywords"
    content="GUI Grounding, GUI Agents, Benchmark Evaluation, Multimodal Large Language Models, User Interface Understanding, Visual Grounding, Hierarchical Taxonomy, Vision-Language Models">
  <meta name="author"
    content="Beitong Zhou, Zhexiao Huang, Yuan Guo, Zhangxuan Gu, Tianyu Xia, Zichen Luo, Fei Tang, Dehan Kong, Yanyi Shang, Suling Ou, Zhenlin Guo, Changhua Meng, Shuheng Shen">
  <meta name="robots" content="index, follow">
  <meta name="language" content="English">

  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="article">
  <meta property="og:site_name" content="AntGroup inclusionAI">
  <meta property="og:title"
    content="VenusBench-GD: A Comprehensive Multi-Platform GUI Benchmark for Diverse Grounding Tasks">
  <meta property="og:description"
    content="VenusBench-GD addresses the limitations of existing GUI grounding benchmarks by introducing a large-scale, bilingual, and cross-platform evaluation framework that utilizes a rigorous high-quality data construction pipeline. The study proposes a novel hierarchical taxonomy encompassing six subtasks across basic and advanced categories, specifically designed to evaluate models on functional understanding and multi-step reasoning. Key experimental findings reveal that while general-purpose multimodal models have reached performance saturation on basic tasks, specialized GUI modelsâ€”though capable in advanced scenariosâ€”suffer from significant overfitting and poor robustness, underscoring the necessity of this comprehensive, multi-tiered framework for future GUI agent development.">
  <meta property="og:url" content="https://ui-venus.github.io/VenusBench-GD/">
  <meta property="og:image" content="https://ui-venus.github.io/VenusBench-GD/static/images/framework.png">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:image:alt"
    content="VenusBench-GD: A Comprehensive Multi-Platform GUI Benchmark for Diverse Grounding Tasks - Research Preview">
  
  <meta property="article:published_time" content="2025-12-18T13:09:09Z">
  <meta property="article:author" content="Beitong Zhou">
  <meta property="article:section" content="Research">
  <meta property="article:tag" content="GUI Agent">
  <meta property="article:tag" content="Grounding Benchmark">

  <!-- Twitter -->
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:site" content="@inclusionAI">
  <!-- <meta name="twitter:creator" content="@AUTHOR_TWITTER_HANDLE"> -->
  <meta name="twitter:title"
    content="VenusBench-GD: A Comprehensive Multi-Platform GUI Benchmark for Diverse Grounding Tasks">
  <meta name="twitter:description"
    content="VenusBench-GD addresses the limitations of existing GUI grounding benchmarks by introducing a large-scale, bilingual, and cross-platform evaluation framework that utilizes a rigorous high-quality data construction pipeline. The study proposes a novel hierarchical taxonomy encompassing six subtasks across basic and advanced categories, specifically designed to evaluate models on functional understanding and multi-step reasoning. Key experimental findings reveal that while general-purpose multimodal models have reached performance saturation on basic tasks, specialized GUI modelsâ€”though capable in advanced scenariosâ€”suffer from significant overfitting and poor robustness, underscoring the necessity of this comprehensive, multi-tiered framework for future GUI agent development.">
  <meta name="twitter:image" content="https://ui-venus.github.io/VenusBench-GD/static/images/framework.png">
  <meta name="twitter:image:alt"
    content="VenusBench-GD: A Comprehensive Multi-Platform GUI Benchmark for Diverse Grounding Tasks - Research Preview">

  <!-- Academic/Research Specific -->
  <meta name="citation_title"
    content="VenusBench-GD: A Comprehensive Multi-Platform GUI Benchmark for Diverse Grounding Tasks">

  <meta name="citation_author" content="Zhou, Beitong">
  <meta name="citation_author" content="Huang, Zhexiao">
  <meta name="citation_author" content="Guo, Yuan">
  <meta name="citation_author" content="Gu, Zhangxuan">
  <meta name="citation_author" content="Xia, Tianyu">
  <meta name="citation_author" content="Luo, Zichen">
  <meta name="citation_author" content="Tang, Fei">
  <meta name="citation_author" content="Kong, Dehan">
  <meta name="citation_author" content="Shang, Yanyi">
  <meta name="citation_author" content="Ou, Suling">
  <meta name="citation_author" content="Guo, Zhenlin">
  <meta name="citation_author" content="Meng, Changhua">
  <meta name="citation_author" content="Shen, Shuheng">

  <meta name="citation_publication_date" content="2025">
  <meta name="citation_conference_title" content="arXiv">
  <meta name="citation_pdf_url" content="https://arxiv.org/pdf/2512.16501">

  <!-- Additional SEO -->
  <meta name="theme-color" content="#2563eb">
  <meta name="msapplication-TileColor" content="#2563eb">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="default">

  <!-- Preconnect for performance -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="preconnect" href="https://ajax.googleapis.com">
  <link rel="preconnect" href="https://documentcloud.adobe.com">
  <link rel="preconnect" href="https://cdn.jsdelivr.net">

  <title>VenusBench-GD: A Comprehensive Multi-Platform GUI Benchmark for Diverse Grounding Tasks - Beitong Zhou, Zhexiao
    Huang, Yuan Guo, Zhangxuan Gu, Tianyu Xia, Zichen Luo, Fei Tang, Dehan Kong, Yanyi Shang, Suling Ou, Zhenlin Guo,
    Changhua Meng, Shuheng Shen | Academic Research</title>

  <!-- Favicon and App Icons -->
  <link rel="icon" type="image/x-icon" href="static/images/ui-venus-logo.ico">
  <link rel="apple-touch-icon" href="static/images/ui-venus-logo.ico">

  <!-- Critical CSS - Load synchronously -->
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <!-- Non-critical CSS - Load asynchronously -->
  <link rel="preload" href="static/css/bulma-carousel.min.css" as="style"
    onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/bulma-slider.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/fontawesome.all.min.css" as="style"
    onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" as="style"
    onload="this.onload=null;this.rel='stylesheet'">

  <!-- Fallback for browsers that don't support preload -->
  <noscript>
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  </noscript>

  <!-- Fonts - Optimized loading -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">

  <!-- Defer non-critical JavaScript -->
  <script defer src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script defer src="static/js/bulma-carousel.min.js"></script>
  <script defer src="static/js/bulma-slider.min.js"></script>
  <script defer src="static/js/index.js"></script>

  <!-- Structured Data for Academic Papers -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "ScholarlyArticle",
    "headline": "PAPER_TITLE",
    "description": "BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS",
    "author": [
      {
        "@type": "Person",
        "name": "FIRST_AUTHOR_NAME",
        "affiliation": {
          "@type": "Organization",
          "name": "INSTITUTION_NAME"
        }
      },
      {
        "@type": "Person",
        "name": "SECOND_AUTHOR_NAME",
        "affiliation": {
          "@type": "Organization",
          "name": "INSTITUTION_NAME"
        }
      }
    ],
    "datePublished": "2024-01-01",
    "publisher": {
      "@type": "Organization",
      "name": "CONFERENCE_OR_JOURNAL_NAME"
    },
    "url": "https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE",
    "image": "https://YOUR_DOMAIN.com/static/images/social_preview.png",
    "keywords": ["KEYWORD1", "KEYWORD2", "KEYWORD3", "machine learning", "computer vision"],
    "abstract": "FULL_ABSTRACT_TEXT_HERE",
    "citation": "BIBTEX_CITATION_HERE",
    "isAccessibleForFree": true,
    "license": "https://creativecommons.org/licenses/by/4.0/",
    "mainEntity": {
      "@type": "WebPage",
      "@id": "https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE"
    },
    "about": [
      {
        "@type": "Thing",
        "name": "RESEARCH_AREA_1"
      },
      {
        "@type": "Thing", 
        "name": "RESEARCH_AREA_2"
      }
    ]
  }
  </script>

  <!-- Website/Organization Structured Data -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Organization",
    "name": "INSTITUTION_OR_LAB_NAME",
    "url": "https://YOUR_INSTITUTION_WEBSITE.com",
    "logo": "https://YOUR_DOMAIN.com/static/images/favicon.ico",
    "sameAs": [
      "https://twitter.com/YOUR_TWITTER_HANDLE",
      "https://github.com/YOUR_GITHUB_USERNAME"
    ]
  }
  </script>
</head>

<body>


  <!-- Scroll to Top Button -->
  <button class="scroll-to-top" onclick="scrollToTop()" title="Scroll to top" aria-label="Scroll to top">
    <i class="fas fa-chevron-up"></i>
  </button>

  <!-- More Works Dropdown -->
  <div class="more-works-container">
    <button class="more-works-btn" onclick="toggleMoreWorks()" title="View More Works from Our Team">
      <i class="fas fa-flask"></i>
      More Works
      <i class="fas fa-chevron-down dropdown-arrow"></i>
    </button>
    <div class="more-works-dropdown" id="moreWorksDropdown">
      <div class="dropdown-header">
        <h4>More Works from Our Team</h4>
        <button class="close-btn" onclick="toggleMoreWorks()">
          <i class="fas fa-times"></i>
        </button>
      </div>
      <div class="works-list">
        <a href="https://arxiv.org/abs/2508.10833" class="work-item" target="_blank">
          <div class="work-info">
            <h5>UI-Venus Technical Report: Building High-performance UI Agents with RFT</h5>
            <p>UI-Venus is a new, SOTA open-source native UI agent leveraging Qwen2.5-VL and RFT to deliver top
              performance in UI grounding and navigation, supported by a novel Self-Evolving Trajectory framework for
              enhanced planning.</p>
            <span class="work-venue">arXiv 2025</span>
          </div>
          <i class="fas fa-external-link-alt"></i>
        </a>
      </div>
    </div>
  </div>

  <main id="main-content">
    <section class="hero">
      <div class="hero-body">
        <div class="container is-max-desktop">
          <div class="columns is-centered">
            <div class="column has-text-centered">
              <h1 class="title is-1 publication-title">VenusBench-GD: A Comprehensive Multi-Platform GUI Benchmark for
                Diverse Grounding Tasks</h1>

              <div class="is-size-5 publication-authors">
                <span class="author-block">
                  <a href="" target="_blank">Beitong Zhou</a><sup>*</sup>,
                </span>
                <span class="author-block">
                  <a href="" target="_blank">Zhexiao Huang</a><sup>*</sup>,
                </span>
                <span class="author-block">
                  <a href="" target="_blank">Yuan Guo</a><sup>*</sup>,
                </span>
                <span class="author-block">
                  <a href="" target="_blank">Zhangxuan Gu</a><sup>*</sup>,
                </span>
                <span class="author-block">
                  <a href="" target="_blank">Tianyu Xia</a>,
                </span>
                <span class="author-block">
                  <a href="" target="_blank">Zichen Luo</a>,
                </span>
                <span class="author-block">
                  <a href="" target="_blank">Fei Tang</a>,
                </span>
                <span class="author-block">
                  <a href="" target="_blank">Dehan Kong</a>,
                </span>
                <span class="author-block">
                  <a href="" target="_blank">Yanyi Shang</a>,
                </span>
                <span class="author-block">
                  <a href="" target="_blank">Suling Ou</a>,
                </span>
                <span class="author-block">
                  <a href="" target="_blank">Zhenlin Guo</a>,
                </span>
                <span class="author-block">
                  <a href="" target="_blank">Changhua Meng</a>,
                </span>
                <span class="author-block">
                  <a href="" target="_blank">Shuheng Shen</a>
                </span>
              </div>

              <div class="is-size-5 publication-authors">
                <span class="author-block">
                  Venus Team, Ant Group<br>
                  arXiv 2025
                </span>
                <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
              </div>

              <div class="column has-text-centered">
                <div class="publication-links">
                  <span class="link-block">
                    <a href="https://arxiv.org/pdf/2512.16501" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Paper</span>
                    </a>
                  </span>

                  <span class="link-block">
                    <a href="https://github.com/inclusionAI/UI-Venus" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fab fa-github"></i>
                      </span>
                      <span>Code</span>
                    </a>
                  </span>

                  <span class="link-block">
                    <a href="https://arxiv.org/abs/2512.16501" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="ai ai-arxiv"></i>
                      </span>
                      <span>arXiv</span>
                    </a>
                  </span>

                  <span class="link-block">
                    <a href="https://huggingface.co/datasets/inclusionAI/VenusBench-GD" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon" style="vertical-align: middle; font-size: 20px;">ðŸ¤—</span>
                      <span>Dataset</span>
                    </a>
                  </span>

                  <span class="link-block">
                    <a href="https://huggingface.co/spaces/inclusionAI/VenusBench-GD-Leaderboard" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-trophy"></i>
                      </span>
                      <span>Leaderboard</span>
                    </a>
                  </span>

                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>


    <!-- VenusBench-GD framework -->
    <section class="hero teaser">
      <div class="container is-max-desktop">
        <div class="hero-body">
          <img src="static/images/framework.png" alt="VenusBench-GD benchmark" />
          <h2 class="subtitle">
            <strong>The overview of VenusBench-GD benchmark.</strong> VenusBench-GD integrates basic and advanced grounding tasks to comprehensively evaluation the capabilities of existing GUI models. Basic tasks assess the ability to recognize local UI elements, while advanced tasks require holistic reasoning over the entire interface and its underlying application functionality, demanding a more complex and global understanding.
          </h2>
        </div>
      </div>
    </section>
    <!-- End framework -->

    <!-- Dataset Statistics -->
    <!-- <section class="hero is-light">
      <div class="container is-max-desktop">
        <div class="hero-body">
          <h2 class="title is-3">Dataset Statistics</h2>
          <div class="columns is-vcentered">
            <div class="column is-half">
              <div class="stats-grid">
                <div class="stat-card">
                  <div class="stat-number">3</div>
                  <div class="stat-label">Platforms</div>
                </div>
                <div class="stat-card">
                  <div class="stat-number">10</div>
                  <div class="stat-label">Domains</div>
                </div>
                <div class="stat-card">
                  <div class="stat-number">93</div>
                  <div class="stat-label">Applications</div>
                </div>
                <div class="stat-card">
                  <div class="stat-number">6100+</div>
                  <div class="stat-label">Sample Pairs</div>
                </div>
              </div>
            </div>
            
            <div class="column is-half">
              <div class="chart-container">
                <img src="static/images/category_sunburst.png" alt="Domain Distribution Pie Chart" loading="lazy" />
                <h4 class="subtitle has-text-centered" style="margin-top: 1rem; font-size: 0.9rem;">
                  Domain distribution across the VenusBench-GD dataset
                </h4>
              </div>
            </div>
          </div>
          <h3 class="subtitle has-text-centered" style="margin-top: 2rem;">
            Each application is represented by multiple screenshots capturing different states and functionalities, ensuring comprehensive coverage of UI components and interaction patterns.
          </h3>
        </div>
      </div>
    </section> -->
    <!-- End Dataset Statistics -->

    <!-- Paper abstract -->
    <section class="section hero is-light">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column">
            <h2 class="title is-3">Abstract</h2>
            <div class="content has-text-justified">
              <p>
                GUI grounding is a critical component in building capable GUI agents. However, existing grounding benchmarks suffer from
                significant limitations: they either provide insufficient data volume and narrow domain coverage, or focus excessively
                on a single platform and require highly specialized domain knowledge. In this work, we present <strong>VenusBench-GD</strong>, a
                comprehensive, bilingual benchmark for GUI grounding that spans multiple platforms, enabling hierarchical evaluation for
                real-word applications. VenusBench-GD contributes as follows: <strong>(i)</strong> we introduce a large-scale, cross-platform benchmark
                with extensive coverage of applications, diverse UI elements, and rich annotated data, <strong>(ii)</strong> we establish a high-quality
                data construction pipeline for grounding tasks, achieving higher annotation accuracy than existing benchmarks, and <strong>(iii)</strong>
                we extend the scope of element grounding by proposing a hierarchical task taxonomy that divides grounding into basic and
                advanced categories, encompassing six distinct subtasks designed to evaluate models from complementary perspectives. Our
                experimental findings reveal critical insights: general-purpose multimodal models now match or even surpass specialized
                GUI models on basic grounding tasks. In contrast, advanced tasks, still favor GUI-specialized models, though they
                exhibit significant overfitting and poor robustness. These results underscore the necessity of comprehensive,
                multi-tiered evaluation frameworks.
              </p>
            </div>
          </div>
        </div>
      </div>
    </section>
    <!-- End paper abstract -->


    <!-- Benchmark Statistics -->
    <section class="hero teaser">
      <div class="container is-max-desktop">
        <div class="hero-body">
          <h2 class="title is-3">Benchmark Statistics</h2>
          <img src="static/images/benchmark_statistics.png" alt="benchmark statistics" />
          <h2 class="subtitle">
            <strong>The dataset statistics</strong> of VenusBench-GD reveal a diverse and challenging distribution across key dimensions. a) The image resolutions span a wide range, with a significant proportion concentrated in common screen sizes. b) UI element sizes vary substantially relative to the image area, covering a broad spectrum from very small to large elements. c) Meanwhile, instruction lengths exhibit a rich distribution, peaking in mid-length queries but extending to longer, more complex descriptions.
          </h2>
        </div>
      </div>
    </section>
    <!-- End Benchmark Statistics -->

    <!-- Performance Figures -->
    <section class="hero is-small is-light">
      <div class="hero-body">
        <div class="container">
          <h2 class="title is-3">Performance Comparison</h2>
          <div class="columns is-multiline">
            <!-- Left Column -->
            <div class="column is-half">
              <div class="result-item">
                <img src="static/images/radar_chart.png" alt="Radar Chart" loading="lazy" />
                <p>
                  The performance of <strong>representative models</strong> on advanced grounding tasks are significantly lower than on basic tasks, highlighting the increased difficulty and reasoning demands.
                </p>
              </div>
            </div>
            
            <!-- Right Column -->
            <div class="column is-half">
              <div class="result-item">
                <img src="static/images/human_performance.png" alt="Human Performance" loading="lazy" />
                <p>
                  <strong>Humane Performance</strong> vs. state-of-the-art (SOTA) on grounding tasks. A significant performance gap persists, particularly in advanced grounding scenarios.
                </p>
              </div>
            </div>
            
          </div>
        </div>
      </div>
    </section>
    <!-- End Performance Figures -->


    <!-- Video carousel -->
    <section class="hero is-small">
      <div class="hero-body">
        <div class="container">
          <h2 class="title is-3">Experimental Results</h2>
          <img src="static/images/experiment_results.png" alt="Experimental Results" />
          <h2 class="subtitle has-text-centered">
            Performance comparison on VenusBench-GD dataset categorized by the evaluation tasks.
          </h2>

        </div>
      </div>
    </section>
    <!-- End video carousel -->

    <!--BibTex citation -->
    <section class="section" id="BibTeX">
      <div class="container is-max-desktop content">
        <div class="bibtex-header">
          <h2 class="title">BibTeX</h2>
          <button class="copy-bibtex-btn" onclick="copyBibTeX()" title="Copy BibTeX to clipboard">
            <i class="fas fa-copy"></i>
            <span class="copy-text">Copy</span>
          </button>
        </div>
        <pre id="bibtex-code"><code>@misc{zhou2025venusbenchgdcomprehensivemultiplatformgui,
      title={VenusBench-GD: A Comprehensive Multi-Platform GUI Benchmark for Diverse Grounding Tasks}, 
      author={Beitong Zhou and Zhexiao Huang and Yuan Guo and Zhangxuan Gu and Tianyu Xia and Zichen Luo and Fei Tang and Dehan Kong and Yanyi Shang and Suling Ou and Zhenlin Guo and Changhua Meng and Shuheng Shen},
      year={2025},
      eprint={2512.16501},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2512.16501}, 
}

</code></pre>
      </div>
    </section>
    <!--End BibTex citation -->


    <footer class="footer">
      <div class="container">
        <div class="columns is-centered">
          <div class="column is-8">
            <div class="content">

              <p>
                This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template"
                  target="_blank">Academic Project Page Template</a> which was adopted from theÂ <a
                  href="https://nerfies.github.io" target="_blank">Nerfies</a>Â project page.
                You are free to borrow the source code of this website, we just ask that you link back to this page in
                the footer. <br> This website is licensed under a <a rel="license"
                  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
                  Commons Attribution-ShareAlike 4.0 International License</a>.
              </p>

            </div>
          </div>
        </div>
      </div>
    </footer>

    <!-- Statcounter tracking code -->

    <!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

</body>

</html>